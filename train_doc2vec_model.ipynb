{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "LabeledSentence = gensim.models.doc2vec.LabeledSentence\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from spacy.en import English\n",
    "from spacy.parts_of_speech import NOUN\n",
    "from spacy.parts_of_speech import VERB\n",
    "nlp = English()\n",
    "probs = [lex.prob for lex in nlp.vocab]\n",
    "probs.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainDF = pd.read_csv('sentenceTrainDF.csv')\n",
    "testDF = pd.read_csv('sentenceTestDF.csv')\n",
    "unsup_amazonDF = pd.read_csv('amazon_sentenceDF_spacy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1045212, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsup_amazonDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train = trainDF.text.values\n",
    "y_train_text = list(map(literal_eval, trainDF.categorys.tolist()))\n",
    "y_train = mlb.transform(y_train_text)\n",
    "\n",
    "x_test = testDF.text.values\n",
    "y_test_text = list(map(literal_eval, testDF.categorys.tolist()))\n",
    "y_test = mlb.transform(y_test_text)\n",
    "\n",
    "unsup_sentences = unsup_amazonDF.sentence.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Do some very minor text preprocessing\n",
    "def cleanText(corpus):\n",
    "    punctuation = \"\"\".,?!:;(){}[]\"\"\"\n",
    "    corpus = [z.lower().replace('\\n','') for z in corpus]\n",
    "    corpus = [z.replace('<br />', ' ') for z in corpus]\n",
    "\n",
    "    #treat punctuation as individual words\n",
    "    for c in punctuation:\n",
    "        corpus = [z.replace(c, ' %s '%c) for z in corpus]\n",
    "    corpus = [z.split() for z in corpus]\n",
    "    return corpus\n",
    "\n",
    "x_train = cleanText(x_train)\n",
    "x_test = cleanText(x_test)\n",
    "unsup_sentences = cleanText(unsup_sentences)\n",
    "\n",
    "#Gensim's Doc2Vec implementation requires each document/paragraph to have a label associated with it.\n",
    "#We do this by using the LabeledSentence method. The format will be \"TRAIN_i\" or \"TEST_i\" where \"i\" is\n",
    "#a dummy index of the review.\n",
    "def labelizeSentences(sentences, label_type):\n",
    "    labelized = []\n",
    "    for i,v in enumerate(sentences):\n",
    "        label = '%s_%s'%(label_type,i)\n",
    "        labelized.append(LabeledSentence(v, [label]))\n",
    "    return labelized\n",
    "\n",
    "x_train = labelizeSentences(x_train, 'TRAIN')\n",
    "x_test = labelizeSentences(x_test, 'TEST')\n",
    "unsup_sentences = labelizeSentences(unsup_sentences, 'UNSUP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1739"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "size = 400\n",
    "\n",
    "#instantiate our DM and DBOW models\n",
    "model_dm = gensim.models.Doc2Vec(min_count=1, window=10, size=size, sample=1e-3, negative=5, workers=3)\n",
    "model_dbow = gensim.models.Doc2Vec(min_count=1, window=10, size=size, sample=1e-3, negative=5, dm=0, workers=3)\n",
    "\n",
    "#build vocab over all sentences\n",
    "model_dm.build_vocab(x_train+ x_test+ unsup_sentences)\n",
    "model_dbow.build_vocab(x_train+ x_test+ unsup_sentences)\n",
    "\n",
    "#We pass through the data set multiple times, controlling the learning rate\n",
    "all_train_sentences = x_train + unsup_sentences\n",
    "for epoch in range(10):\n",
    "    model_dm.train(all_train_sentences)\n",
    "    model_dbow.train(all_train_sentences)\n",
    "    model_dm.alpha -= 0.002  # decrease the learning rate\n",
    "    model_dbow.alpha -= 0.002  # decrease the learning rate\n",
    "    model_dm.min_alpha = model_dm.alpha  # fix the learning rate, no decay\n",
    "    model_dbow.min_alpha = model_dbow.alpha  # fix the learning rate, no decay\n",
    "    \n",
    "#Get training set vectors from our models\n",
    "def getVecs(model, corpus, size):\n",
    "    vecs = [np.array(model.docvecs[z.tags[0]]).reshape((1, size)) for z in corpus]\n",
    "    return np.concatenate(vecs)\n",
    "\n",
    "train_vecs_dm = getVecs(model_dm, x_train, size)\n",
    "train_vecs_dbow = getVecs(model_dbow, x_train, size)\n",
    "train_vecs = np.hstack((train_vecs_dm, train_vecs_dbow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train over test set\n",
    "\n",
    "Idx=list(range(len(x_test)))\n",
    "\n",
    "for epoch in range(10):\n",
    "    random.shuffle(Idx)\n",
    "    perm_sentences = [x_test[i] for i in Idx]\n",
    "    model_dm.train(perm_sentences)\n",
    "    model_dbow.train(perm_sentences)\n",
    "\n",
    "#Construct vectors for test sentences\n",
    "test_vecs_dm = getVecs(model_dm, x_test, size)\n",
    "test_vecs_dbow = getVecs(model_dbow, x_test, size)\n",
    "test_vecs = np.hstack((test_vecs_dm, test_vecs_dbow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dm.save('nmodel_dm.d2v')\n",
    "model_dbow.save('nmodel_dbow.d2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25602992090955001"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dm.docvecs.similarity('TRAIN_1', 'TRAIN_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = model_dm.docvecs.most_similar('TRAIN_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabeledSentence(['this', 'is', 'absolutely', 'amazing', 'laptop', '!', '!', '!'], ['UNSUP_716972'])\n",
      "LabeledSentence(['i', 'absolutely', 'love', 'this', 'computer', '!', '!', '!'], ['UNSUP_775798'])\n",
      "LabeledSentence(['this', 'computer', 'is', 'amazing', '!', '!'], ['UNSUP_606812'])\n",
      "LabeledSentence(['this', 'laptop', 'is', 'absolutely', 'amazing', '!'], ['UNSUP_745655'])\n",
      "LabeledSentence(['i', 'absolutely', 'love', 'this', 'computer', '!', '!', '!', '!'], ['UNSUP_401717'])\n",
      "LabeledSentence(['i', 'absolutely', 'love', 'this', 'computer', '.'], ['UNSUP_904161'])\n",
      "LabeledSentence(['absolutely', 'love', 'this', 'computer', '!', '!', '!'], ['UNSUP_102374'])\n",
      "LabeledSentence(['this', 'computer', 'is', 'amazing', '!'], ['UNSUP_558751'])\n",
      "LabeledSentence(['i', 'absolutely', 'love', 'this', 'computer', '!'], ['UNSUP_616560'])\n",
      "LabeledSentence(['this', 'computer', 'is', 'amazing', '!'], ['UNSUP_100267'])\n"
     ]
    }
   ],
   "source": [
    "for s in result:\n",
    "    index = int(s[0].replace('UNSUP_',''))\n",
    "    print(unsup_sentences[index])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
